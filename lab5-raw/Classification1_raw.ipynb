{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision tensorboard torchmetrics"
      ],
      "metadata": {
        "id": "J0saV9BzOSVp",
        "outputId": "9bc8a7ae-a849-4589-9009-eddb54c64c01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Downloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "iAF-FZKQZUtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Iv054njYZTcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load CIFAR-100 Dataset"
      ],
      "metadata": {
        "id": "MHcqrCDAZX5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762))  # CIFAR-100 normalization values\n",
        "])\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "batch_size = ...\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = ...\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = ...\n",
        "\n",
        "# Define a function to visualize some samples from the dataset\n",
        "def imshow(img):\n",
        "    ...\n",
        "\n",
        "# Show some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "imshow(torchvision.utils.make_grid(images[:8]))  # Show 8 images in a grid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb3PV0WBZZj8",
        "outputId": "9a93a597-bf2b-48a5-8403-ee5b626eb2d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Model"
      ],
      "metadata": {
        "id": "JW2gzdPHZkoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-defined ResNet18 model and adjust it for CIFAR-100\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "# Define the model\n",
        "model = resnet18()  # Set num_classes to 100 for CIFAR-100\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ... # set the model on cuda"
      ],
      "metadata": {
        "id": "n0buf69gZeev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the model"
      ],
      "metadata": {
        "id": "5W8roxhXPAdn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_2R7MscaPTHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Model"
      ],
      "metadata": {
        "id": "uWjUX51zPTKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-defined ResNet18 model and adjust it for CIFAR-100\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "# Define the model\n",
        "model = resnet18(pretrained=True)  # Set num_classes to 100 for CIFAR-100\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec7763e-f250-4acb-a93f-1c1732858707",
        "id": "Shpt3N3_PTKs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 193MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters_in_millions(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return total_params / 1_000_000  # Divide by 1 million to convert to millions\n",
        "\n",
        "# Example usage:\n",
        "total_params_in_millions = count_parameters_in_millions(model)\n",
        "print(f'Total trainable parameters: {total_params_in_millions:.2f} million')"
      ],
      "metadata": {
        "id": "UkemH3SfbbrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Linear(model.fc.in_features, 100)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "AbwyAV_YPTKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Parameters"
      ],
      "metadata": {
        "id": "RvQvxBTkZ0qQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print model parameters\n",
        "print(\"Model Parameters:\")\n",
        "for name, param in model.named_parameters():\n",
        "  print(f\"Name: {name}, Shape: {param.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtL4G_tcZ0YW",
        "outputId": "5877a53b-9df2-427a-8a32-900f1a5f86c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Parameters:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Linear(model.fc.in_features, 100)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "tNlDJScEx7fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Loss Function, Optimizer, and TensorBoard Writer"
      ],
      "metadata": {
        "id": "Yg-oaEWpZm7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = ...\n",
        "# optimizer = optim.Adam(model.fc.parameters(), lr=0.1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Initialize TensorBoard writer\n",
        "writer = SummaryWriter('runs/cifar100_resnet18')"
      ],
      "metadata": {
        "id": "e1YZOnxqZncv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save a checkpoint in the TensorBoard log directory\n",
        "def save_checkpoint(model, optimizer, epoch, loss_metric, accuracy_metric, checkpoint_dir='runs/cifar100_resnet18'):\n",
        "    checkpoint_path = f\"{checkpoint_dir}/checkpoint_epoch_{epoch+1}.pth\"\n",
        "\n",
        "    # Use .compute() to get the values of the metrics\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'loss': loss_metric.compute(),  # Get the computed loss\n",
        "        'accuracy': accuracy_metric.compute()  # Get the computed accuracy\n",
        "    }\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    print(f'Checkpoint saved at {checkpoint_path}')\n",
        "\n",
        "# Function to load a checkpoint from the TensorBoard log directory\n",
        "def load_checkpoint(model, optimizer, checkpoint_dir='runs/cifar100_resnet18'):\n",
        "    import glob\n",
        "    # Find the latest checkpoint (e.g., based on the highest epoch number)\n",
        "    checkpoint_paths = glob.glob(f\"{checkpoint_dir}/checkpoint_epoch_*.pth\")\n",
        "    checkpoint_paths.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
        "    latest_checkpoint = checkpoint_paths[-1]\n",
        "\n",
        "    checkpoint = torch.load(latest_checkpoint)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1  # Resume from the next epoch\n",
        "    loss = checkpoint['loss']\n",
        "    accuracy = checkpoint['accuracy']\n",
        "    print(f'Checkpoint loaded from {latest_checkpoint}. Resuming training from epoch {start_epoch}')\n",
        "\n",
        "    return start_epoch, loss, accuracy  # You can return these for reference but don't update accuracy_metric with them"
      ],
      "metadata": {
        "id": "cn_cSC--QXul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Updated training function with torchmetrics and resuming capability\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=1, start_epoch=0, resume=False, checkpoint_dir='runs/cifar100_resnet18'):\n",
        "    # Initialize the metrics\n",
        "    loss_metric = torchmetrics.MeanMetric()\n",
        "    accuracy_metric = torchmetrics.Accuracy()\n",
        "\n",
        "    # Load checkpoint if resuming\n",
        "    if resume:\n",
        "        ...\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)"
      ],
      "metadata": {
        "id": "V0kyX-UtQkf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion, optimizer, checkpoint_dir='runs/cifar100_resnet18'):\n",
        "    # Load the model from the latest checkpoint if needed\n",
        "    load_checkpoint(model, optimizer, checkpoint_dir)\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)"
      ],
      "metadata": {
        "id": "M2xbMQhnQ_SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_feature_maps(model, layer_name, image):\n",
        "    # Get the specified layer's output\n",
        "    activation = {}\n",
        "    def hook_fn(module, input, output):\n",
        "        activation[layer_name] = output\n",
        "\n",
        "    layer = dict(model.named_modules())[layer_name]\n",
        "    layer.register_forward_hook(hook_fn)\n",
        "\n",
        "    # Pass the image through the model\n",
        "    image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "    model(image)\n",
        "\n",
        "    # Extract and plot the feature maps\n",
        "    feature_maps = activation[layer_name].squeeze().cpu().detach()\n",
        "    fig, axes = plt.subplots(1, min(8, feature_maps.size(0)), figsize=(15, 15))\n",
        "    for i in range(min(8, feature_maps.size(0))):\n",
        "        axes[i].imshow(feature_maps[i], cmap='viridis')\n",
        "        axes[i].axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gkw5zXwxRPy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def visualize_tsne(model, loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            features.extend(output.cpu().numpy())\n",
        "            labels.extend(targets.numpy())\n",
        "\n",
        "    # Convert the list of features into a numpy array\n",
        "    features = np.array(features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Perform t-SNE\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    tsne_results = tsne.fit_transform(features)\n",
        "\n",
        "    # Create a DataFrame for visualization\n",
        "    df = pd.DataFrame({'x': tsne_results[:, 0], 'y': tsne_results[:, 1], 'label': labels})\n",
        "\n",
        "    # Plot the t-SNE results using seaborn\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.scatterplot(x='x', y='y', hue='label', palette='tab10', data=df, legend='full', alpha=0.7)\n",
        "    plt.title('t-SNE of MobileNetV2 Features')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "GWjwU_hoRSSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_incorrect_predictions(model, loader, max_samples=10):\n",
        "    model.eval()\n",
        "    incorrect_samples = []\n",
        "    incorrect_labels = []\n",
        "    incorrect_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            # TODO complete this function\n",
        "            ...\n",
        "\n",
        "    return incorrect_samples, incorrect_labels, incorrect_preds\n",
        "\n",
        "\n",
        "def visualize_incorrect_predictions(model, loader, class_names, max_samples=10):\n",
        "    incorrect_samples, incorrect_labels, incorrect_preds = get_incorrect_predictions(model, loader, max_samples=max_samples)\n",
        "\n",
        "    # Plot the images with true and predicted labels\n",
        "    fig, axes = plt.subplots(1, len(incorrect_samples), figsize=(15, 5))\n",
        "    if len(incorrect_samples) == 1:\n",
        "        axes = [axes]  # To handle the case where there's only one incorrect sample\n",
        "\n",
        "    for idx, (img, true_label, pred_label) in enumerate(zip(incorrect_samples, incorrect_labels, incorrect_preds)):\n",
        "        img = img.permute(1, 2, 0)  # Convert from (C, H, W) to (H, W, C)\n",
        "        img = img * 0.2673 + 0.5071  # Unnormalize for CIFAR100: (std_dev * image + mean)\n",
        "        img = np.clip(img, 0, 1)\n",
        "\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].set_title(f'True: {class_names[true_label]}\\nPred: {class_names[pred_label]}', fontsize=10)\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "E74VjTJXRZOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training from scratch\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10, resume=False, checkpoint_dir='runs/cifar100_resnet18')\n",
        "\n",
        "# If training gets interrupted, resume from the last checkpoint:\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10, resume=True, checkpoint_dir='runs/cifar100_resnet18')"
      ],
      "metadata": {
        "id": "ThJz2OkvSEmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Start TensorBoard and point it to the log directory used by SummaryWriter\n",
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "rH-J-uZXSGv0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}